{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "MNVMY6aTqVI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from scipy.stats import norm\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.mixture import GaussianMixture as GMM\n",
        "import numpy as np\n",
        "import os\n",
        "!pip install torchsummary\n",
        "import  torchsummary as tt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import scipy.io\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import h5py\n",
        "import math\n",
        "import time\n",
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "!pip install mat73\n",
        "import mat73\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n"
      ],
      "metadata": {
        "id": "gAibCOswFdDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c89d41-52a9-46da-db1f-36cc62428f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Widgets"
      ],
      "metadata": {
        "id": "RGoY2u6grOp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST,WS_D,NS_D,D, Scores\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "def SourceK():\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST\n",
        "    p=interact(CCS,CCF=widgets.Dropdown(\n",
        "        options=['Yellow', 'QUGS', 'Z24'],\n",
        "        value='Yellow',\n",
        "        description='Source Class',\n",
        "        disabled=False,\n",
        "        style=dict(description_width='initial')\n",
        "    ));\n",
        "\n",
        "def SourceKT():\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST\n",
        "    p=interact(CCT,CCF=widgets.Dropdown(\n",
        "        options=['Yellow', 'QUGS', 'Z24'],\n",
        "        value='Yellow',\n",
        "        description='Target Class',\n",
        "        disabled=False,\n",
        "        style=dict(description_width='initial')\n",
        "    ));\n",
        "\n",
        "def NK():\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST\n",
        "    p=interact(CCN,CCF=widgets.Dropdown(\n",
        "        options=['15', '10', '6'],\n",
        "        value='15',\n",
        "        description='Source N',\n",
        "        disabled=False,\n",
        "        style=dict(description_width='initial')\n",
        "    ));\n",
        "\n",
        "def WK():\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST\n",
        "    p=interact(CCW,CCF=widgets.Dropdown(\n",
        "        options=['2000', '1000', '500'],\n",
        "        value='2000',\n",
        "        description='Source W',\n",
        "        disabled=False,\n",
        "        style=dict(description_width='initial')\n",
        "    ));\n",
        "\n",
        "def CCS(CCF):\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST\n",
        "    if (CCF=='Yellow'):\n",
        "        CL1=1\n",
        "    if (CCF=='QUGS'):\n",
        "        CL1=2\n",
        "    if (CCF=='Z24'):\n",
        "        CL1=3\n",
        "    SS=CL1\n",
        "    Source=CCF\n",
        "\n",
        "def CCT(CCF):\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST\n",
        "    if (CCF=='Yellow'):\n",
        "        CL1=1\n",
        "    if (CCF=='QUGS'):\n",
        "        CL1=2\n",
        "    if (CCF=='Z24'):\n",
        "        CL1=3\n",
        "    ST=CL1\n",
        "    Target=CCF\n",
        "\n",
        "\n",
        "def CCN(CCF):\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST,NS_D,D,WS_D,D,NN_C,N\n",
        "    if (CCF=='15'):\n",
        "        CL1=1\n",
        "    if (CCF=='10'):\n",
        "        CL1=2\n",
        "    if (CCF=='6'):\n",
        "        CL1=3\n",
        "    NS=CL1\n",
        "    NS_D=int(CCF)\n",
        "    N=NS_D\n",
        "\n",
        "def CCW(CCF):\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST,WS_D,NN_C,Spec,D,NS_D,W,Scores\n",
        "    if (CCF=='2000'):\n",
        "        CL1=1\n",
        "    if (CCF=='1000'):\n",
        "        CL1=2\n",
        "    if (CCF=='500'):\n",
        "        CL1=3 \n",
        "    WS=CL1\n",
        "    WS_D=int(CCF)\n",
        "    W=WS_D\n",
        "\n",
        "global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST,NS_D,WS_D\n",
        "def Source_Plots():\n",
        "    global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST,NS_D,WS_D\n",
        "    inverse_buttonSS = widgets.Button(description='Source_Plots',style=dict(description_width='initial'))\n",
        "    def inverse_button_clicked(change):\n",
        "      global Source, Target, DMS,DMT, ZetS,ZetT,E1S,E1T,ZopS,ZopT, path_M,S,W,SS,NS,WS,ST,NS_D,WS_D\n",
        "      [DMS, ZetS, E1S, ZopS]=Load_Data(Source,NS_D,WS_D,path_M)\n",
        "      [DMT, ZetT, E1T, ZopT]=Load_Data(Target,NS_T,WS_T,path_M)\n",
        "    inverse_buttonSS.on_click(inverse_button_clicked)\n",
        "    display(inverse_buttonSS)\n"
      ],
      "metadata": {
        "id": "lWWbHZYKrPlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep networks for all $W$ and $N$ values\n",
        "* N=5, 10, 15\n",
        "* Dynamic regarding W"
      ],
      "metadata": {
        "id": "Yh_5q4jBaBqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR GENERATOR/DISCRIMINATOR HERE\n",
        "  \n",
        "class CustomNeuralNetworkS15(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        super(CustomNeuralNetworkS15, self).__init__()\n",
        "        Stacked_Layers=1\n",
        "        self.lstm1 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm3 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm4 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm5 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm6 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm7 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm8 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm9 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm10 = nn.LSTM(int(W/2), 100,Stacked_Layers, batch_first=True)\n",
        "        self.lstmCL = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm12= nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm13= nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm14= nn.LSTM(int(W/2), 100,Stacked_Layers, batch_first=True)\n",
        "        self.lstm15 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.Flatten = nn.Flatten()\n",
        "        self.FC1=nn.Linear(1500,100)\n",
        "        self.FC2=nn.Linear(100,1)\n",
        "        self.LR1 = nn.LeakyReLU(0.2)\n",
        "        self.LR2 = nn.LeakyReLU(0.2)\n",
        "        self.Sig=nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out1,state = self.lstm1(x[:,:,0:int(W/2)])\n",
        "        out2,state = self.lstm2(x[:,:,int(W/2):2*int(W/2)])\n",
        "        out3,state = self.lstm3(x[:,:,2*int(W/2):3*int(W/2)])\n",
        "        out4,state = self.lstm4(x[:,:,3*int(W/2):4*int(W/2)])\n",
        "        out5,state = self.lstm5(x[:,:,4*int(W/2):5*int(W/2)])\n",
        "        out6,state = self.lstm6(x[:,:,5*int(W/2):6*int(W/2)])\n",
        "        out7,state = self.lstm7(x[:,:,6*int(W/2):7*int(W/2)])\n",
        "        out8,state = self.lstm8(x[:,:,7*int(W/2):8*int(W/2)])\n",
        "        out9,state = self.lstm9(x[:,:,8*int(W/2):9*int(W/2)])\n",
        "        out10,state = self.lstm10(x[:,:,9*int(W/2):10*int(W/2)])\n",
        "        outCL,state = self.lstm6(x[:,:,10*int(W/2):11*int(W/2)])\n",
        "        out12,state = self.lstm7(x[:,:,11*int(W/2):12*int(W/2)])\n",
        "        out13,state = self.lstm8(x[:,:,12*int(W/2):13*int(W/2)])\n",
        "        out14,state = self.lstm9(x[:,:,13*int(W/2):14*int(W/2)])\n",
        "        out15,state = self.lstm10(x[:,:,14*int(W/2):15*int(W/2)])\n",
        "        LL=torch.cat((out1,out2,out3,out4,out5,out6,out7,out8,out9,out10,outCL,out12,out13,out14,out15),dim=2)\n",
        "        LLA=self.LR1(LL)\n",
        "        outCL=self.Flatten(LLA)\n",
        "        outNF=self.FC1(outCL)\n",
        "        LLB=self.LR1(outNF)        \n",
        "        outF=self.FC2(LLB)\n",
        "        outFF=self.Sig(outF)\n",
        "        return outFF\n",
        "\n",
        "########### 10\n",
        "\n",
        "class CustomNeuralNetworkS10(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        super(CustomNeuralNetworkS10, self).__init__()\n",
        "        Stacked_Layers=1\n",
        "        self.lstm1 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm3 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm4 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm5 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm6 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm7 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm8 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm9 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm10 = nn.LSTM(int(W/2), 100,Stacked_Layers, batch_first=True)\n",
        "        self.Flatten = nn.Flatten()\n",
        "        self.FC1=nn.Linear(1000,100)\n",
        "        self.FC2=nn.Linear(100,1)\n",
        "        self.LR1 = nn.LeakyReLU(0.2)\n",
        "        self.LR2 = nn.LeakyReLU(0.2)\n",
        "        self.Sig=nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out1,state = self.lstm1(x[:,:,0:int(W/2)])\n",
        "        out2,state = self.lstm2(x[:,:,int(W/2):2*int(W/2)])\n",
        "        out3,state = self.lstm3(x[:,:,2*int(W/2):3*int(W/2)])\n",
        "        out4,state = self.lstm4(x[:,:,3*int(W/2):4*int(W/2)])\n",
        "        out5,state = self.lstm5(x[:,:,4*int(W/2):5*int(W/2)])\n",
        "        out6,state = self.lstm6(x[:,:,5*int(W/2):6*int(W/2)])\n",
        "        out7,state = self.lstm7(x[:,:,6*int(W/2):7*int(W/2)])\n",
        "        out8,state = self.lstm8(x[:,:,7*int(W/2):8*int(W/2)])\n",
        "        out9,state = self.lstm9(x[:,:,8*int(W/2):9*int(W/2)])\n",
        "        out10,state = self.lstm10(x[:,:,9*int(W/2):10*int(W/2)])\n",
        "        LL=torch.cat((out1,out2,out3,out4,out5,out6,out7,out8,out9,out10),dim=2)\n",
        "        LLA=self.LR1(LL)\n",
        "        outCL=self.Flatten(LLA)\n",
        "        outNF=self.FC1(outCL)\n",
        "        LLB=self.LR1(outNF)        \n",
        "        outF=self.FC2(LLB)\n",
        "        outFF=self.Sig(outF)\n",
        "        return outFF\n",
        "\n",
        "########### 6\n",
        "\n",
        "class CustomNeuralNetworkS6(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        super(CustomNeuralNetworkS6, self).__init__()\n",
        "        Stacked_Layers=1\n",
        "        self.lstm1 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm3 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm4 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm5 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.lstm6 = nn.LSTM(int(W/2), 100, Stacked_Layers, batch_first=True)\n",
        "        self.Flatten = nn.Flatten()\n",
        "        self.FC1=nn.Linear(600,100)\n",
        "        self.FC2=nn.Linear(100,1)\n",
        "        self.LR1 = nn.LeakyReLU(0.2)\n",
        "        self.LR2 = nn.LeakyReLU(0.2)\n",
        "        self.Sig=nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out1,state = self.lstm1(x[:,:,0:int(W/2)])\n",
        "        out2,state = self.lstm2(x[:,:,int(W/2):2*int(W/2)])\n",
        "        out3,state = self.lstm3(x[:,:,2*int(W/2):3*int(W/2)])\n",
        "        out4,state = self.lstm4(x[:,:,3*int(W/2):4*int(W/2)])\n",
        "        out5,state = self.lstm5(x[:,:,4*int(W/2):5*int(W/2)])\n",
        "        out6,state = self.lstm6(x[:,:,5*int(W/2):6*int(W/2)])\n",
        "        LL=torch.cat((out1,out2,out3,out4,out5,out6),dim=2)\n",
        "        LLA=self.LR1(LL)\n",
        "        outCL=self.Flatten(LLA)\n",
        "        outNF=self.FC1(outCL)\n",
        "        LLB=self.LR1(outNF)        \n",
        "        outF=self.FC2(LLB)\n",
        "        outFF=self.Sig(outF)\n",
        "        return outFF\n",
        "\n",
        "\n",
        "    \n",
        "def generator2000(noise_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(noise_dim,256),\n",
        "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        nn.BatchNorm1d(256, affine=False),\n",
        "        nn.Linear(256,512),\n",
        "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        nn.BatchNorm1d(512, affine=False),\n",
        "        nn.Linear(512,1500),\n",
        "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        nn.BatchNorm1d(1500, affine=False),\n",
        "        nn.Linear(1500,(int(W/2))*N),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "    return model\n",
        "    \n",
        "def generator1000(noise_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(noise_dim,256),\n",
        "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        nn.BatchNorm1d(256, affine=False),\n",
        "        nn.Linear(256,512),\n",
        "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        nn.BatchNorm1d(512, affine=False),\n",
        "        nn.Linear(512,1500),\n",
        "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        nn.BatchNorm1d(1500, affine=False),\n",
        "        nn.Linear(1500,(int(W/2))*N),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def generator500(noise_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(noise_dim,256),\n",
        "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        nn.BatchNorm1d(256, affine=False),\n",
        "        nn.Linear(256,512),\n",
        "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "        nn.BatchNorm1d(512, affine=False),\n",
        "        nn.Linear(512,int(W/2)*N),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "    return model\n",
        "\n",
        "## Neural Network Class\n"
      ],
      "metadata": {
        "id": "bMfuukVrBoDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Functions"
      ],
      "metadata": {
        "id": "ld52e8Z-PQew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* AUC/ROC"
      ],
      "metadata": {
        "id": "HFfXr3GNq-Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC and AUC \n",
        "def ROC_S(Jok,Zet,Wind,CN,Plot):\n",
        "  TestA=Jok\n",
        "  ZetTB=Zet-Zet%Wind\n",
        "  FA=1\n",
        "  T=0\n",
        "  FAA=[]\n",
        "  TAA=[]\n",
        "  while (FA>0):\n",
        "    TestF=TestA[0:int(ZetTB[1]/Wind)]\n",
        "    TestT=TestA[int(ZetTB[1]/Wind)::]\n",
        "    LF=len(TestF)\n",
        "    LT=len(TestT)\n",
        "    FA=len(TestF[TestF>T])/LF\n",
        "    TA=len(TestT[TestT>T])/LT\n",
        "    T=T+0.001\n",
        "    FAA.append(FA)\n",
        "    TAA.append(TA)\n",
        "  FAA.append(0)\n",
        "  TAA.append(0)\n",
        "  if(Plot):\n",
        "    plt.plot(FAA,TAA)\n",
        "    plt.title('ROC curve')\n",
        "    plt.xlabel('False Alarm',fontsize=24)\n",
        "    plt.ylabel('True Alarm',fontsize=24)\n",
        "  F=np.array(FAA)\n",
        "  T=np.array(TAA)\n",
        "\n",
        "  Area=0\n",
        "  F=-F[1:len(F)]+F[0:len(F)-1]\n",
        "  T=(T[1:len(T)]+T[0:len(T)-1])/2\n",
        "  Area=np.sum(abs(T*F))\n",
        "  return(Area,[FAA,TAA])\n",
        "\n",
        "\n",
        "def PR(Jok,Zet,Wind,T):\n",
        "  TestA=Jok\n",
        "  ZetTB=Zet-Zet%Wind\n",
        "  TestF=TestA[0:int(ZetTB[1]/Wind)]\n",
        "  TestT=TestA[int(ZetTB[1]/Wind)::]\n",
        "  N=len(TestF)\n",
        "  P=len(TestT)\n",
        "  FN=len(TestF[TestF>T])\n",
        "  FP=N-FN\n",
        "  TP=len(TestT[TestT>T])\n",
        "  Precision=(TP)/(TP+FP)\n",
        "  Recall=(TP)/(TP+FN)\n",
        "  F1=2*Precision*Recall/(Precision+Recall)\n",
        "  return(Precision, Recall, F1)\n",
        "\n",
        "\n",
        "def PR2(Jok,Zet,Zet_C1,T):\n",
        "  TestA=Jok\n",
        "  TestF=TestA[0:Zet_C1]\n",
        "  TestT=TestA[Zet_C1::]\n",
        "  N=len(TestF)\n",
        "  P=len(TestT)\n",
        "  TP=len(TestT[TestT>T])\n",
        "  FN=P-TP\n",
        "  FP=len(TestF[TestF>T])\n",
        "  TN=N-FP\n",
        "  print('T:\\t',T,'FP:\\t',FP,'TP:\\t',TP,'FN:\\t',FN,'TN:\\t',TN)\n",
        "  TP=len(TestT[TestT>T])\n",
        "  Precision=(TP)/(TP+FP)\n",
        "  Recall=(TP)/(TP+FN)\n",
        "  F1=2*Precision*Recall/(Precision+Recall)\n",
        "  return(Precision, Recall, F1)"
      ],
      "metadata": {
        "id": "rOGzZyFsPQFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The main TL function"
      ],
      "metadata": {
        "id": "kGZ0vo-DZiz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TL_FT(DM,W,S,Zet,D,Source_Spectrum,Precision,TL=False, Plot=False):\n",
        "  if Target==\"Z24\":\n",
        "    Coef=0.5\n",
        "  else:\n",
        "    Coef=0.1\n",
        "  Spec=Source_Spectrum\n",
        "  E1=np.cumsum(Zet)\n",
        "  D_initiation=np.array([E1,np.zeros((len(E1)))])\n",
        "  if TL==False:\n",
        "    print('TL results without FT\\n')\n",
        "    Test=-torch.log10(D(torch.Tensor((DM).reshape(len(DM),1,S*int(W/2)))))\n",
        "    Test[Test>Precision]=Precision\n",
        "    Test=Test.detach().cpu().numpy()\n",
        "    if Plot:\n",
        "      plt.plot(Test)\n",
        "      plt.plot(D_initiation[0,1::],D_initiation[1,1::], 'ro', markersize=12)\n",
        "      plt.xlabel('Data Instance',fontsize=24)\n",
        "      plt.ylabel(\"$S$\",fontsize=24)\n",
        "      plt.legend(['Data','Data class'],fontsize=20)\n",
        "      plt.show()\n",
        "    [AUC,U]=ROC_S(Test,Zet,1,1,Plot)\n",
        "    print('AUC= ',str(AUC))\n",
        "\n",
        "  if TL==True:\n",
        "    print('TL results with FT\\n')\n",
        "    E1=np.cumsum(Zet)\n",
        "    DMU=np.copy(DM)\n",
        "    DMQ=np.copy(DM)\n",
        "    E1Q=np.copy(E1)\n",
        "    G=np.copy(Spec)\n",
        "    DMMCopy=np.copy(DM)\n",
        "\n",
        "    # FT, Algorith 1 --- Spectrum normalization using only the intact data%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "    for k in range(S):\n",
        "      GA=G[k*int(W/2):(k+1)*int(W/2)];\n",
        "      G1=np.mean(DMQ[0:int(E1Q[1]*Coef),k*int(W/2):(k+1)*int(W/2)]**2, axis=0)\n",
        "      G1=G1/np.max(G1)\n",
        "      L=np.argsort(GA)\n",
        "      L1=np.argsort(G1)\n",
        "      Kok=np.zeros((int(W/2),int(W/2)))\n",
        "      for j in range(int(W/2)):\n",
        "        Kok[j,:]=(np.abs(GA-G1[j]))\n",
        "      K=np.argmin(Kok, axis=1)\n",
        "\n",
        "    # Transfroming the rest of dataset suing mapping from the intact portion %%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "      for i in range(int(W/2)):\n",
        "        DMMCopy[:,L[i]+k*int(W/2)]=np.copy(DMQ[:,L1[i]+k*int(W/2)])*np.sqrt(GA[int(L[i])]/G1[int(L1[i])])\n",
        "        \n",
        "    Test=-torch.log10(D(torch.Tensor((DMMCopy).reshape(len(DM),1,S*int(W/2)))))\n",
        "    Test[Test>Precision]=Precision\n",
        "    Test=Test.detach().cpu().numpy()\n",
        "    if Plot:\n",
        "      plt.plot(Test)\n",
        "      plt.plot(D_initiation[0,1::],D_initiation[1,1::], 'ro', markersize=12)\n",
        "      plt.xlabel('Data Instance',fontsize=24)\n",
        "      plt.ylabel(\"$S$\",fontsize=24)\n",
        "      plt.title('Novelty Detection Results')\n",
        "      plt.legend(['Data','Data class'],fontsize=20)\n",
        "      plt.show()\n",
        "    [AUC,U]=ROC_S(Test,Zet,1,1,Plot)\n",
        "    print('AUC= ',str(AUC))"
      ],
      "metadata": {
        "id": "lffJHYyQTUNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset functions"
      ],
      "metadata": {
        "id": "E5q7CSMQZwRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Load_Data(Source,S,W,path_M):\n",
        "  if Source=='Yellow':\n",
        "    CL=21\n",
        "    path=os.path.join(path_M+'Dataset/Yellow_'+'S'+str(N)+'_'+str(W)+'.mat')\n",
        "    data_dict = mat73.loadmat(path)\n",
        "    path3=os.path.join(path_M+'Dataset/Yellow_Classes_'+str(W)+'.mat')\n",
        "    data_dict12 = mat73.loadmat(path3)\n",
        "    Data_CL=np.array(data_dict12[\"Zet\"])[0:CL]\n",
        "    Data_CL=np.concatenate(([0],Data_CL))\n",
        "    E1=np.cumsum(Data_CL)\n",
        "    Max=len(data_dict)\n",
        "    DM=np.array(data_dict[\"C\"][0:int(E1[CL]),:])\n",
        "    E1=np.reshape(E1,(CL+1))\n",
        "    Dop=np.zeros((CL+1))\n",
        "    Zop=np.array([E1,Dop])\n",
        "    DMS=DM\n",
        "    Data_CLS=Data_CL\n",
        "    E1S=E1\n",
        "    ZopS=Zop\n",
        "  if Source=='QUGS':\n",
        "    CL=31\n",
        "    path=os.path.join(path_M+'Dataset/QUGS_'+'S'+str(N)+'_'+str(W)+'.mat')\n",
        "    data_dict = mat73.loadmat(path)\n",
        "    path3=os.path.join(path_M+'Dataset/QUGS_Classes_'+str(W)+'.mat')\n",
        "    data_dict12 = mat73.loadmat(path3)\n",
        "    Data_CL=np.array(data_dict12[\"Zet\"])[0:CL]\n",
        "    Data_CL=np.concatenate(([0],Data_CL))\n",
        "    E1=np.cumsum(Data_CL)\n",
        "    Max=len(data_dict)\n",
        "    DM=np.array(data_dict[\"C\"])\n",
        "    E1=np.reshape(E1,(32))\n",
        "    Dop=np.zeros((32))\n",
        "    Zop=np.array([E1,Dop])\n",
        "    DMS=DM\n",
        "    Data_CLS=Data_CL\n",
        "    E1S=E1\n",
        "    ZopS=Zop\n",
        "\n",
        "  if Source=='Z24':\n",
        "    CL=8\n",
        "    path=os.path.join(path_M+'Dataset/Z24_'+'S'+str(N)+'_'+str(W)+'.mat')\n",
        "    data_dict = mat73.loadmat(path)\n",
        "    path3=os.path.join(path_M+'Dataset/Z24_Classes_'+str(W)+'.mat')\n",
        "    data_dict12 = mat73.loadmat(path3)\n",
        "    Data_CL=np.array(data_dict12[\"Zet\"])[0:CL]\n",
        "    Data_CL=np.concatenate(([0],Data_CL))\n",
        "    E1=np.cumsum(Data_CL)\n",
        "    Max=len(data_dict)\n",
        "    DM=np.array(data_dict[\"C\"])\n",
        "    E1=np.reshape(E1,(CL+1))\n",
        "    Dop=np.zeros((CL+1))\n",
        "    Zop=np.array([E1,Dop])\n",
        "    DMS=DM\n",
        "    Data_CLS=Data_CL\n",
        "    E1S=E1\n",
        "    ZopS=Zop\n",
        "\n",
        "  return DMS, Data_CLS, E1S, ZopS"
      ],
      "metadata": {
        "id": "P8gmBcp0ZyVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load detector function"
      ],
      "metadata": {
        "id": "J_rKbNrr7Zq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Load_Detector = widgets.Button(\n",
        "    description='Load Detector',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='',\n",
        "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
        ")\n",
        "\n",
        "def L_D(val):\n",
        "    global WS_D,NS_D,W,D,NN_C,Spec,Scores\n",
        "    W=WS_D\n",
        "    class NN_C:\n",
        "      def __init__(self):\n",
        "        self.S15 = []\n",
        "        self.S10=[]\n",
        "        self.S5=[]\n",
        "    NN_C.S15=CustomNeuralNetworkS15()\n",
        "    NN_C.S10=CustomNeuralNetworkS10()\n",
        "    NN_C.S6=CustomNeuralNetworkS6()\n",
        "    # You can change DK to only values on the papaer; otherwise, it errs\n",
        "    print('Your detectors is:\\t',Source[0],'D1S',str(NS_D),'_',str(WS_D))\n",
        "    DK='1'\n",
        "    #print(exec('D = CustomNeuralNetworkS%s().to(device)'%(str(NS_D))))\n",
        "    exec('D = NN_C.S%s.to(device)'%(str(NS_D)))\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    checkpoint =torch.load(os.path.join('/content/drive/MyDrive/7thTopic/'+Source+'/LSTM'+str(NS_D)+'_'+str(WS_D)+'/DC'+str(DK)+'/'+'Detector.pth'),map_location=device)\n",
        "    Spec=checkpoint['Spec']\n",
        "    #Scores=checkpoint['Scores']\n",
        "    plt.plot(Spec)\n",
        "    plt.title('Source Spectrum');\n",
        "    plt.xlabel('Spectral Line',fontsize=24);\n",
        "    plt.ylabel('Amplitude',fontsize=24);\n",
        "    E1G=np.cumsum(np.ones((NS_D)))*WS_D/2\n",
        "    D_initiation=np.array([E1G,np.zeros((NS_D))])\n",
        "    plt.plot(D_initiation[0,::],D_initiation[1,:], 'ro', markersize=12)\n",
        "    plt.ylabel('$S$',fontsize=20)\n",
        "    plt.xlabel('Data instance',fontsize=20)\n",
        "    plt.legend(['Frequency Spectrum','Channels'],fontsize=20)\n",
        "    plt.show()\n",
        "    D.load_state_dict(checkpoint['D'])\n",
        "\n",
        "@Load_Detector.on_click\n",
        "\n",
        "def sayhello_onclick(a):\n",
        "    global WS_D,NS_D,W,D\n",
        "    L_D('txtval.value')"
      ],
      "metadata": {
        "id": "bE7YK2Dh7csB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction Function"
      ],
      "metadata": {
        "id": "KtScpHdxUmw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Feature_Ext(Data,Class_N,Capping,W):\n",
        "  # CL is the number of data classes\n",
        "  CL=len(Class_N)-1\n",
        "  N=Data.shape[1]\n",
        "  S=Data.shape[1]\n",
        "  K=np.copy(Data)\n",
        "  i=0\n",
        "  D_C=np.copy(K[(np.cumsum(Class_N))[i]:(np.cumsum(Class_N))[i]+((np.cumsum(Class_N)[i+1])-(np.cumsum(Class_N)[i]))-((np.cumsum(Class_N)[i+1])-(np.cumsum(Class_N)[i]))%W,:])\n",
        "  D_C=D_C.reshape((int(np.floor(D_C.shape[0]/W)),W,N))\n",
        "  D_C=D_C[:,:,:]\n",
        "  D_C=(np.abs(np.fft.fft((D_C),axis=1)))[:,0:int(W/2),:]\n",
        "  for k in range(Data.shape[1]):\n",
        "    D_C[:,:,k]=D_C[:,:,k]/np.mean(D_C[:,:,k],axis=1).reshape((-1,1))\n",
        "  D_C[D_C>Capping]=Capping\n",
        "  DM=np.copy(D_C)\n",
        "  Data_CL=np.asarray(D_C.shape[0]).reshape((1))\n",
        "  for i in range (1,CL):\n",
        "    D_C=np.copy(K[(np.cumsum(Class_N))[i]:(np.cumsum(Class_N))[i]+((np.cumsum(Class_N)[i+1])-(np.cumsum(Class_N)[i]))-((np.cumsum(Class_N)[i+1])-(np.cumsum(Class_N)[i]))%W,:])\n",
        "    D_C=D_C.reshape((int(np.floor(D_C.shape[0]/W)),W,N))\n",
        "    D_C=D_C[:,:,:]\n",
        "    D_C=(np.abs(np.fft.fft((D_C),axis=1)))[:,0:int(W/2),:]\n",
        "    for k in range(Data.shape[1]):\n",
        "      D_C[:,:,k]=D_C[:,:,k]/np.mean(D_C[:,:,k],axis=1).reshape((-1,1))\n",
        "    D_C[D_C>Capping]=Capping\n",
        "    DM=np.concatenate((DM,D_C),axis=0)\n",
        "    Data_CL=np.concatenate((Data_CL,np.asarray(D_C.shape[0]).reshape((1))),axis=0)\n",
        "  DM=np.swapaxes(DM,1,2)\n",
        "  DM=DM.reshape((DM.shape[0],int(W/2)*N))\n",
        "  Data_CL=np.concatenate(([0],Data_CL))\n",
        "  E1=np.cumsum(Data_CL)\n",
        "  #E1=E1.reshape((len(E1),1))\n",
        "  return DM,Data_CL,E1,S,CL"
      ],
      "metadata": {
        "id": "oJoHhU7MUokQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ROC all cases"
      ],
      "metadata": {
        "id": "jaAvnPmzI_6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ROC_All(DMT,WS_D,NS_D,E1T,Data_CLT,D,Spec,Precision,TL=True):\n",
        "  AUCP=[]\n",
        "  CL=len(E1T)-1\n",
        "  E1=np.copy(E1T)\n",
        "  for Class in range(1,CL):\n",
        "    DM=DMT\n",
        "    W=WS_D\n",
        "    S=NS_D\n",
        "    Zet=np.copy(Data_CLT)\n",
        "    E1Q=np.copy(E1T)\n",
        "    Source_Spectrum=Spec\n",
        "    Precision=80\n",
        "    Plot=False\n",
        "    if Target==\"Z24\":\n",
        "      Coef=0.5\n",
        "    else:\n",
        "      Coef=0.1\n",
        "    D_initiation=np.array([E1,np.zeros((len(E1)))])\n",
        "    print('DC'+str(Class)+' TL results with FT')\n",
        "    E1=np.cumsum(Zet)\n",
        "    DMU=np.copy(DM)\n",
        "    DMQ=np.copy(DM)\n",
        "    E1Q=np.copy(E1)\n",
        "    G=np.copy(Spec)\n",
        "    DMMCopy=np.copy(DM)\n",
        "\n",
        "    # FT, Algorith 1 --- Spectrum normalization using only the intact data%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "    for k in range(S):\n",
        "      GA=G[k*int(W/2):(k+1)*int(W/2)];\n",
        "      G1=np.mean(DMQ[0:int(E1Q[1]*Coef),k*int(W/2):(k+1)*int(W/2)]**2, axis=0)\n",
        "      G1=G1/np.max(G1)*100\n",
        "      L=np.argsort(GA)\n",
        "      L1=np.argsort(G1)\n",
        "      Kok=np.zeros((int(W/2),int(W/2)))\n",
        "      for j in range(int(W/2)):\n",
        "        Kok[j,:]=(np.abs(GA-G1[j]))\n",
        "      K=np.argmin(Kok, axis=1)\n",
        "\n",
        "    # Transfroming the rest of dataset suing mapping from the intact portion %%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "      if TL:\n",
        "        for i in range(int(W/2)):\n",
        "          DMMCopy[:,L[i]+k*int(W/2)]=np.copy(DMQ[:,L1[i]+k*int(W/2)])*np.sqrt(GA[int(L[i])]/G1[int(L1[i])])\n",
        "    E1QS=np.cumsum(E1Q)\n",
        "    DOLO=np.concatenate((DMMCopy[int(E1Q[1]*Coef):int(E1Q[1]),:],DMMCopy[int(E1Q[Class]):int(E1Q[Class+1]),:]))   \n",
        "    Test=-torch.log10(D(torch.Tensor((DOLO).reshape(len(DOLO),1,S*int(W/2)))))\n",
        "    Test[Test>Precision]=Precision\n",
        "    Test=Test.detach().cpu().numpy()\n",
        "    Zet=np.array([0,int(E1Q[1])-int(E1Q[1]*Coef),E1Q[Class+1]-E1Q[Class]])\n",
        "    Zet\n",
        "    if Plot:\n",
        "      plt.plot(Test)\n",
        "      plt.plot(D_initiation[0,1::],D_initiation[1,1::], 'ro', markersize=12)\n",
        "      plt.xlabel('Data Instance',fontsize=24)\n",
        "      plt.ylabel(\"$S$\",fontsize=24)\n",
        "      plt.title('Novelty Detection Results')\n",
        "      plt.legend(['Data','Data class'],fontsize=20)\n",
        "      plt.show()\n",
        "    [AUC,U]=ROC_S(Test,Zet,1,1,Plot)\n",
        "    AUCP.append(AUC)\n",
        "    print('AUC= ',str(AUC),'\\n')\n",
        "    A=([U[0]])[0]\n",
        "    B=([U[1]])[0]\n",
        "    plt.plot(A,B)\n",
        "    plt.title('All cases ROC curves')\n",
        "    plt.xlabel('False Alarm',fontsize=24)\n",
        "    plt.ylabel('True Alarm',fontsize=24)\n",
        "  print('Mean AUC= ',str(np.mean(AUCP)),'\\n')"
      ],
      "metadata": {
        "id": "OkOPO4kgg8jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer Learning-Binary SDD"
      ],
      "metadata": {
        "id": "HzgSGRzo0bnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Binary_SDD(DMT,WS_D,NS_D,E1T,Data_CLT,D,Spec,Precision,TL=True):\n",
        "  CL=len(E1T)-1\n",
        "  PP=np.zeros((CL,1))\n",
        "  RR=np.zeros((CL,1))\n",
        "  FF=np.zeros((CL,1))\n",
        "  E1=np.copy(E1T)\n",
        "  for Class in range(1,CL):\n",
        "    DM=DMT\n",
        "    W=WS_D\n",
        "    S=NS_D\n",
        "    Zet=np.copy(Data_CLT)\n",
        "    E1Q=np.copy(E1T)\n",
        "    Source_Spectrum=Spec\n",
        "    Plot=False\n",
        "    if Target.find(\"Z24\")==-1:\n",
        "      Coef=0.1\n",
        "    else:\n",
        "      Coef=0.5\n",
        "    Coef2=0.4\n",
        "    D_initiation=np.array([E1,np.zeros((len(E1)))])\n",
        "    #print('TL results with FT\\n')\n",
        "    E1=np.cumsum(Zet)\n",
        "    DMU=np.copy(DM)\n",
        "    DMQ=np.copy(DM)\n",
        "    E1Q=np.copy(E1)\n",
        "    G=np.copy(Spec)\n",
        "    DMMCopy=np.copy(DM)\n",
        "\n",
        "    # FT, Algorith 1 --- Spectrum normalization using only the intact data%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "    for k in range(S):\n",
        "      GA=G[k*int(W/2):(k+1)*int(W/2)];\n",
        "      G1=np.mean(DMQ[0:int(E1Q[1]*Coef),k*int(W/2):(k+1)*int(W/2)]**2, axis=0)\n",
        "      G1=G1/np.max(G1)\n",
        "      L=np.argsort(GA)\n",
        "      L1=np.argsort(G1)\n",
        "      Kok=np.zeros((int(W/2),int(W/2)))\n",
        "      for j in range(int(W/2)):\n",
        "        Kok[j,:]=(np.abs(GA-G1[j]))\n",
        "      K=np.argmin(Kok, axis=1)\n",
        "\n",
        "    # Transfroming the rest of dataset suing mapping from the intact portion %%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "      if TL:\n",
        "        for i in range(int(W/2)):\n",
        "          DMMCopy[:,L[i]+k*int(W/2)]=np.copy(DMQ[:,L1[i]+k*int(W/2)])*np.sqrt(GA[int(L[i])]/G1[int(L1[i])])\n",
        "      else:\n",
        "        pass\n",
        "    G111=(DMMCopy[int(E1Q[1]*Coef):int(E1Q[1]*(Coef+Coef2)),:])\n",
        "    Test111=-torch.log10(D(torch.Tensor((G111).reshape(len(G111),1,S*int(W/2)))))\n",
        "    TestAll=-torch.log10(D(torch.Tensor((DMMCopy).reshape(len(DMMCopy),1,S*int(W/2)))))\n",
        "    mu, std = norm.fit(Test111.detach().cpu())\n",
        "    KK=max(0.31,mu+3*std)\n",
        "    if TL:\n",
        "      print('DC'+str(Class)+' TL results with FT')\n",
        "    else:\n",
        "      print('DC'+str(Class)+' TL results without FT')\n",
        "    E1QS=np.cumsum(E1Q)\n",
        "    DOLO=np.concatenate((DMMCopy[int(E1Q[1]*(Coef+Coef2)):int(E1Q[1]),:],DMMCopy[int(E1Q[Class]):int(E1Q[Class+1]),:]))   \n",
        "    Test=-torch.log10(D(torch.Tensor((DOLO).reshape(len(DOLO),1,S*int(W/2)))))\n",
        "    Test[Test>Precision]=Precision\n",
        "    Test=Test.detach().cpu().numpy()\n",
        "    Zet=np.array([0,int(E1Q[1])-int(E1Q[1]*(Coef+Coef2)),E1Q[Class+1]-E1Q[Class]])\n",
        "    print('SDD results with Damage class:\\t',str(Class))\n",
        "    plt.plot(Test)\n",
        "    #plt.ylim([0,0.5])\n",
        "    Zet_C1=Zet[1]\n",
        "    plt.plot([0,Zet_C1+Zet[2]],[KK,KK],'r')\n",
        "    plt.show()\n",
        "    [PP[Class],RR[Class],FF[Class]]=PR2(Test,Zet,int(Zet_C1),KK)\n",
        "    print('Precision= ',str(PP[Class]),'Recall= ',str(RR[Class]),'F1=',str(FF[Class]),'\\n\\n\\n')\n",
        "\n",
        "  plt.plot(PP)\n",
        "  plt.plot(RR)\n",
        "  plt.plot(FF)\n",
        "  plt.xlim([1,CL])\n",
        "  plt.title('Accuracy Metrics')\n",
        "  plt.xlabel('Damage case',fontsize=24)\n",
        "  plt.ylabel('PRF',fontsize=24)\n",
        "  plt.legend(['Precision','Recall','F1'],fontsize=20)"
      ],
      "metadata": {
        "id": "Wg7XZp2b0c6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
